{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_keywords = []\n",
    "with open(\"看漲關鍵字.txt\",'r',encoding = 'UTF8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        up_keywords.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_keywords = []\n",
    "with open(\"看跌關鍵字.txt\",'r',encoding = 'UTF8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        down_keywords.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = up_keywords + down_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_news = pd.read_csv('看漲-幅度大於2%.csv')\n",
    "down_news = pd.read_csv('看跌-幅度大於2%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_news['year'] = pd.DatetimeIndex(up_news['normalized_time']).year\n",
    "up_news['month'] = pd.DatetimeIndex(up_news['normalized_time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# up_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_news['year'] = pd.DatetimeIndex(down_news['normalized_time']).year\n",
    "down_news['month'] = pd.DatetimeIndex(down_news['normalized_time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dict = {2016: {}, 2017: {}, 2018: {}, 2019: {}, 2020: {}}\n",
    "\n",
    "\n",
    "for year in range(2016, 2021):\n",
    "    for month in range(1, 13):\n",
    "        up = up_news.loc[(up_news['year'] == year) & (up_news['month'] == month)]\n",
    "        down = down_news.loc[(down_news['year'] == year) & (down_news['month'] == month)]\n",
    "        size = len(up) + len(down)\n",
    "        size_dict[year][month] = size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>42</td>\n",
       "      <td>114</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>149</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>108</td>\n",
       "      <td>65</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>219</td>\n",
       "      <td>79</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>140</td>\n",
       "      <td>137</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>124</td>\n",
       "      <td>46</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>194</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2016  2017  2018  2019  2020\n",
       "1      3    69    16    78    91\n",
       "2      0    99     1    74     0\n",
       "3      8    58    18   114    39\n",
       "4      2    61    42   114    19\n",
       "5      5    12    39   149    13\n",
       "6     14    30   108    65    42\n",
       "7      2    14   219    79    55\n",
       "8      0    97    59    60    22\n",
       "9      8   140   137    48    19\n",
       "10     0    48   107    34    11\n",
       "11    57    30   124    46    23\n",
       "12    67    30    64   194     6"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(size_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_1719 = []\n",
    "\n",
    "for year in range(2017, 2020):\n",
    "    for month in range(1, 13):\n",
    "        up = up_news.loc[(up_news['year'] == year) & (up_news['month'] == month)]\n",
    "        down = down_news.loc[(down_news['year'] == year) & (down_news['month'] == month)]\n",
    "        size = len(up) + len(down)\n",
    "\n",
    "        size_1719.append([year, month, size])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2017, 1, 69],\n",
       " [2017, 2, 99],\n",
       " [2017, 3, 58],\n",
       " [2017, 4, 61],\n",
       " [2017, 5, 12],\n",
       " [2017, 6, 30],\n",
       " [2017, 7, 14],\n",
       " [2017, 8, 97],\n",
       " [2017, 9, 140],\n",
       " [2017, 10, 48],\n",
       " [2017, 11, 30],\n",
       " [2017, 12, 30],\n",
       " [2018, 1, 16],\n",
       " [2018, 2, 1],\n",
       " [2018, 3, 18],\n",
       " [2018, 4, 42],\n",
       " [2018, 5, 39],\n",
       " [2018, 6, 108],\n",
       " [2018, 7, 219],\n",
       " [2018, 8, 59],\n",
       " [2018, 9, 137],\n",
       " [2018, 10, 107],\n",
       " [2018, 11, 124],\n",
       " [2018, 12, 64],\n",
       " [2019, 1, 78],\n",
       " [2019, 2, 74],\n",
       " [2019, 3, 114],\n",
       " [2019, 4, 114],\n",
       " [2019, 5, 149],\n",
       " [2019, 6, 65],\n",
       " [2019, 7, 79],\n",
       " [2019, 8, 60],\n",
       " [2019, 9, 48],\n",
       " [2019, 10, 34],\n",
       " [2019, 11, 46],\n",
       " [2019, 12, 194]]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_1719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(size_1719)\n",
    "train_size = 5\n",
    "iteration = total - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent): # 不切 ngram\n",
    "    sent = re.sub(r'[^\\w]',\"\",sent)\n",
    "    sent = re.sub(r'[A-Za-z0-9]',\"\",sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "with open(\"stopwords.TXT\",'r',encoding = 'UTF8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopwords.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_vec(news, y):\n",
    "    news_vec = []\n",
    "\n",
    "    for index, row in news.iterrows():\n",
    "        text_vec = []\n",
    "        content = preprocess(row[\"title\"] + row[\"content\"])\n",
    "\n",
    "        data = {\n",
    "            'index': index,\n",
    "            'date': row['normalized_time'],\n",
    "            'year': row['year'],\n",
    "            'month': row['month'],\n",
    "            'title': row['title'],\n",
    "            'content': row['content'],\n",
    "            'y': y\n",
    "        }\n",
    "\n",
    "        for word in word_vec:\n",
    "            data[word] = 0\n",
    "            if word in content:\n",
    "                data[word] = 1\n",
    "\n",
    "        news_vec.append(data)\n",
    "    return news_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(data, file_name, file_type):\n",
    "    base_data = data[data.columns[:7]]\n",
    "    base_data.to_csv(r'基本資料_' + file_type + '_' + file_name + '.csv', index = False)\n",
    "    n = 0 - len(word_vec)\n",
    "    X = data[data.columns[n:]]\n",
    "    X.to_csv(r'X_' + file_type + '_' +  file_name + '.csv', index = False)\n",
    "    data['y'].to_csv(r'Y_' + file_type + '_' + file_name + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(up_news.loc[(up_news['year'] == year) & (up_news['month'] == month)]['content'])\n",
    "# word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = []\n",
    "\n",
    "for i in range(iteration):\n",
    "    up = pd.concat([\n",
    "        up_news.loc[(up_news['year'] == size_1719[i][0]) & (up_news['month'] == size_1719[i][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+1][0]) & (up_news['month'] == size_1719[i+1][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+2][0]) & (up_news['month'] == size_1719[i+2][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+3][0]) & (up_news['month'] == size_1719[i+3][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+4][0]) & (up_news['month'] == size_1719[i+4][1])],\n",
    "    ],axis = 0)\n",
    "    \n",
    "    down = pd.concat([\n",
    "        down_news.loc[(down_news['year'] == size_1719[i][0]) & (down_news['month'] == size_1719[i][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+1][0]) & (down_news['month'] == size_1719[i+1][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+2][0]) & (down_news['month'] == size_1719[i+2][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+3][0]) & (down_news['month'] == size_1719[i+3][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+4][0]) & (down_news['month'] == size_1719[i+4][1])],\n",
    "    ],axis = 0)\n",
    "    \n",
    "    up_test = up_news.loc[(up_news['year'] == size_1719[i+5][0]) & (up_news['month'] == size_1719[i+5][1])]\n",
    "    down_test = down_news.loc[(down_news['year'] == size_1719[i+5][0]) & (down_news['month'] == size_1719[i+5][1])]\n",
    "    \n",
    "    news_vec = get_news_vec(up, 1)\n",
    "    news_vec += get_news_vec(down, -1)\n",
    "\n",
    "    news_vec_test = get_news_vec(up_test, 1)\n",
    "    news_vec_test += get_news_vec(down_test, -1)\n",
    "    \n",
    "    train_data = pd.DataFrame(news_vec)\n",
    "    test_data = pd.DataFrame(news_vec_test)\n",
    "\n",
    "    duration = str(size_1719[i][0]) + '.' + str(size_1719[i][1]) + '~' + str(size_1719[i+4][0]) + '.' + str(size_1719[i+4][1])\n",
    "    export_data(train_data, str(i), 'training')\n",
    "    export_data(test_data, str(i), 'testing')\n",
    "    duration_data.append({\n",
    "        'file_index': i,\n",
    "        'training_duration': duration,\n",
    "        'testing_duration': str(size_1719[i+5][0]) + '.' + str(size_1719[i+5][1]),\n",
    "        'training_size': len(train_data),\n",
    "        'testing_size': len(test_data)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_pd = pd.DataFrame(duration_data)\n",
    "duration_pd.to_csv(r'檔名及區間紀錄.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = []\n",
    "\n",
    "for i in range(iteration-1):\n",
    "    up = pd.concat([\n",
    "        up_news.loc[(up_news['year'] == size_1719[i][0]) & (up_news['month'] == size_1719[i][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+1][0]) & (up_news['month'] == size_1719[i+1][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+2][0]) & (up_news['month'] == size_1719[i+2][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+3][0]) & (up_news['month'] == size_1719[i+3][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+4][0]) & (up_news['month'] == size_1719[i+4][1])],\n",
    "    ],axis = 0)\n",
    "    \n",
    "    down = pd.concat([\n",
    "        down_news.loc[(down_news['year'] == size_1719[i][0]) & (down_news['month'] == size_1719[i][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+1][0]) & (down_news['month'] == size_1719[i+1][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+2][0]) & (down_news['month'] == size_1719[i+2][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+3][0]) & (down_news['month'] == size_1719[i+3][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+4][0]) & (down_news['month'] == size_1719[i+4][1])],\n",
    "    ],axis = 0)\n",
    "    \n",
    "    up_test = pd.concat([\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+5][0]) & (up_news['month'] == size_1719[i+5][1])],\n",
    "        up_news.loc[(up_news['year'] == size_1719[i+6][0]) & (up_news['month'] == size_1719[i+6][1])],\n",
    "    ],axis = 0)\n",
    "    down_test = pd.concat([\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+5][0]) & (down_news['month'] == size_1719[i+5][1])],\n",
    "        down_news.loc[(down_news['year'] == size_1719[i+6][0]) & (down_news['month'] == size_1719[i+6][1])],\n",
    "    ],axis = 0)\n",
    "    \n",
    "    news_vec = get_news_vec(up, 1)\n",
    "    news_vec += get_news_vec(down, -1)\n",
    "\n",
    "    news_vec_test = get_news_vec(up_test, 1)\n",
    "    news_vec_test += get_news_vec(down_test, -1)\n",
    "    \n",
    "    train_data = pd.DataFrame(news_vec)\n",
    "    test_data = pd.DataFrame(news_vec_test)\n",
    "\n",
    "    duration = str(size_1719[i][0]) + '.' + str(size_1719[i][1]) + '~' + str(size_1719[i+4][0]) + '.' + str(size_1719[i+4][1])\n",
    "    export_data(train_data, str(i), 'training')\n",
    "    export_data(test_data, str(i), 'testing')\n",
    "    duration_data.append({\n",
    "        'file_index': i,\n",
    "        'training_duration': duration,\n",
    "        'testing_duration': str(size_1719[i+5][0]) + '.' + str(size_1719[i+5][1]) + '~' + str(size_1719[i+6][0]) + '.' + str(size_1719[i+6][1]),\n",
    "        'training_size': len(train_data),\n",
    "        'testing_size': len(test_data)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_index': 0,\n",
       "  'training_duration': '2017.1~2017.5',\n",
       "  'testing_duration': '2017.6~2017.7',\n",
       "  'training_size': 299,\n",
       "  'testing_size': 44},\n",
       " {'file_index': 1,\n",
       "  'training_duration': '2017.2~2017.6',\n",
       "  'testing_duration': '2017.7~2017.8',\n",
       "  'training_size': 260,\n",
       "  'testing_size': 111},\n",
       " {'file_index': 2,\n",
       "  'training_duration': '2017.3~2017.7',\n",
       "  'testing_duration': '2017.8~2017.9',\n",
       "  'training_size': 175,\n",
       "  'testing_size': 237},\n",
       " {'file_index': 3,\n",
       "  'training_duration': '2017.4~2017.8',\n",
       "  'testing_duration': '2017.9~2017.10',\n",
       "  'training_size': 214,\n",
       "  'testing_size': 188},\n",
       " {'file_index': 4,\n",
       "  'training_duration': '2017.5~2017.9',\n",
       "  'testing_duration': '2017.10~2017.11',\n",
       "  'training_size': 293,\n",
       "  'testing_size': 78},\n",
       " {'file_index': 5,\n",
       "  'training_duration': '2017.6~2017.10',\n",
       "  'testing_duration': '2017.11~2017.12',\n",
       "  'training_size': 329,\n",
       "  'testing_size': 60},\n",
       " {'file_index': 6,\n",
       "  'training_duration': '2017.7~2017.11',\n",
       "  'testing_duration': '2017.12~2018.1',\n",
       "  'training_size': 329,\n",
       "  'testing_size': 46},\n",
       " {'file_index': 7,\n",
       "  'training_duration': '2017.8~2017.12',\n",
       "  'testing_duration': '2018.1~2018.2',\n",
       "  'training_size': 345,\n",
       "  'testing_size': 17},\n",
       " {'file_index': 8,\n",
       "  'training_duration': '2017.9~2018.1',\n",
       "  'testing_duration': '2018.2~2018.3',\n",
       "  'training_size': 264,\n",
       "  'testing_size': 19},\n",
       " {'file_index': 9,\n",
       "  'training_duration': '2017.10~2018.2',\n",
       "  'testing_duration': '2018.3~2018.4',\n",
       "  'training_size': 125,\n",
       "  'testing_size': 60},\n",
       " {'file_index': 10,\n",
       "  'training_duration': '2017.11~2018.3',\n",
       "  'testing_duration': '2018.4~2018.5',\n",
       "  'training_size': 95,\n",
       "  'testing_size': 81},\n",
       " {'file_index': 11,\n",
       "  'training_duration': '2017.12~2018.4',\n",
       "  'testing_duration': '2018.5~2018.6',\n",
       "  'training_size': 107,\n",
       "  'testing_size': 147},\n",
       " {'file_index': 12,\n",
       "  'training_duration': '2018.1~2018.5',\n",
       "  'testing_duration': '2018.6~2018.7',\n",
       "  'training_size': 116,\n",
       "  'testing_size': 327},\n",
       " {'file_index': 13,\n",
       "  'training_duration': '2018.2~2018.6',\n",
       "  'testing_duration': '2018.7~2018.8',\n",
       "  'training_size': 208,\n",
       "  'testing_size': 278},\n",
       " {'file_index': 14,\n",
       "  'training_duration': '2018.3~2018.7',\n",
       "  'testing_duration': '2018.8~2018.9',\n",
       "  'training_size': 426,\n",
       "  'testing_size': 196},\n",
       " {'file_index': 15,\n",
       "  'training_duration': '2018.4~2018.8',\n",
       "  'testing_duration': '2018.9~2018.10',\n",
       "  'training_size': 467,\n",
       "  'testing_size': 244},\n",
       " {'file_index': 16,\n",
       "  'training_duration': '2018.5~2018.9',\n",
       "  'testing_duration': '2018.10~2018.11',\n",
       "  'training_size': 562,\n",
       "  'testing_size': 231},\n",
       " {'file_index': 17,\n",
       "  'training_duration': '2018.6~2018.10',\n",
       "  'testing_duration': '2018.11~2018.12',\n",
       "  'training_size': 630,\n",
       "  'testing_size': 188},\n",
       " {'file_index': 18,\n",
       "  'training_duration': '2018.7~2018.11',\n",
       "  'testing_duration': '2018.12~2019.1',\n",
       "  'training_size': 646,\n",
       "  'testing_size': 142},\n",
       " {'file_index': 19,\n",
       "  'training_duration': '2018.8~2018.12',\n",
       "  'testing_duration': '2019.1~2019.2',\n",
       "  'training_size': 491,\n",
       "  'testing_size': 152},\n",
       " {'file_index': 20,\n",
       "  'training_duration': '2018.9~2019.1',\n",
       "  'testing_duration': '2019.2~2019.3',\n",
       "  'training_size': 510,\n",
       "  'testing_size': 188},\n",
       " {'file_index': 21,\n",
       "  'training_duration': '2018.10~2019.2',\n",
       "  'testing_duration': '2019.3~2019.4',\n",
       "  'training_size': 447,\n",
       "  'testing_size': 228},\n",
       " {'file_index': 22,\n",
       "  'training_duration': '2018.11~2019.3',\n",
       "  'testing_duration': '2019.4~2019.5',\n",
       "  'training_size': 454,\n",
       "  'testing_size': 263},\n",
       " {'file_index': 23,\n",
       "  'training_duration': '2018.12~2019.4',\n",
       "  'testing_duration': '2019.5~2019.6',\n",
       "  'training_size': 444,\n",
       "  'testing_size': 214},\n",
       " {'file_index': 24,\n",
       "  'training_duration': '2019.1~2019.5',\n",
       "  'testing_duration': '2019.6~2019.7',\n",
       "  'training_size': 529,\n",
       "  'testing_size': 144},\n",
       " {'file_index': 25,\n",
       "  'training_duration': '2019.2~2019.6',\n",
       "  'testing_duration': '2019.7~2019.8',\n",
       "  'training_size': 516,\n",
       "  'testing_size': 139},\n",
       " {'file_index': 26,\n",
       "  'training_duration': '2019.3~2019.7',\n",
       "  'testing_duration': '2019.8~2019.9',\n",
       "  'training_size': 521,\n",
       "  'testing_size': 108},\n",
       " {'file_index': 27,\n",
       "  'training_duration': '2019.4~2019.8',\n",
       "  'testing_duration': '2019.9~2019.10',\n",
       "  'training_size': 467,\n",
       "  'testing_size': 82},\n",
       " {'file_index': 28,\n",
       "  'training_duration': '2019.5~2019.9',\n",
       "  'testing_duration': '2019.10~2019.11',\n",
       "  'training_size': 401,\n",
       "  'testing_size': 80},\n",
       " {'file_index': 29,\n",
       "  'training_duration': '2019.6~2019.10',\n",
       "  'testing_duration': '2019.11~2019.12',\n",
       "  'training_size': 286,\n",
       "  'testing_size': 240}]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_pd = pd.DataFrame(duration_data)\n",
    "duration_pd.to_csv(r'檔名及區間紀錄.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
