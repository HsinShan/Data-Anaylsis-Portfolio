{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_Resort</th>\n",
       "      <th>hotel_City</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>stays_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>meal_BB</th>\n",
       "      <th>meal_FB</th>\n",
       "      <th>...</th>\n",
       "      <th>wait_less_than_3</th>\n",
       "      <th>wait_between_3_30</th>\n",
       "      <th>wait_greater_than_30</th>\n",
       "      <th>contract</th>\n",
       "      <th>group</th>\n",
       "      <th>transient</th>\n",
       "      <th>transient_party</th>\n",
       "      <th>mean_required_car_parking_space</th>\n",
       "      <th>special_requests_ratio</th>\n",
       "      <th>quatity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015/7/1</th>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>190.291262</td>\n",
       "      <td>27</td>\n",
       "      <td>3.048544</td>\n",
       "      <td>1.805825</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.184466</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015/7/2</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>69.944444</td>\n",
       "      <td>27</td>\n",
       "      <td>5.694444</td>\n",
       "      <td>1.972222</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015/7/3</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>65.378378</td>\n",
       "      <td>27</td>\n",
       "      <td>4.324324</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015/7/4</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>120.777778</td>\n",
       "      <td>27</td>\n",
       "      <td>5.311111</td>\n",
       "      <td>1.977778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015/7/5</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>75.378378</td>\n",
       "      <td>28</td>\n",
       "      <td>6.108108</td>\n",
       "      <td>1.945946</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/3/27</th>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>96.368421</td>\n",
       "      <td>13</td>\n",
       "      <td>2.982456</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.675439</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/3/28</th>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>52.537313</td>\n",
       "      <td>13</td>\n",
       "      <td>3.820896</td>\n",
       "      <td>1.791045</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/3/29</th>\n",
       "      <td>51</td>\n",
       "      <td>79</td>\n",
       "      <td>41.130769</td>\n",
       "      <td>13</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.653846</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.484615</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/3/30</th>\n",
       "      <td>51</td>\n",
       "      <td>73</td>\n",
       "      <td>59.137097</td>\n",
       "      <td>13</td>\n",
       "      <td>3.596774</td>\n",
       "      <td>1.725806</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>19</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/3/31</th>\n",
       "      <td>64</td>\n",
       "      <td>76</td>\n",
       "      <td>58.053846</td>\n",
       "      <td>13</td>\n",
       "      <td>3.084615</td>\n",
       "      <td>1.846154</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              hotel_Resort  hotel_City   lead_time  arrival_date_week_number  \\\n",
       "arrival_date                                                                   \n",
       "2015/7/1                38          65  190.291262                        27   \n",
       "2015/7/2                35           1   69.944444                        27   \n",
       "2015/7/3                27          10   65.378378                        27   \n",
       "2015/7/4                36           9  120.777778                        27   \n",
       "2015/7/5                37           0   75.378378                        28   \n",
       "...                    ...         ...         ...                       ...   \n",
       "2017/3/27               25          89   96.368421                        13   \n",
       "2017/3/28               33          34   52.537313                        13   \n",
       "2017/3/29               51          79   41.130769                        13   \n",
       "2017/3/30               51          73   59.137097                        13   \n",
       "2017/3/31               64          76   58.053846                        13   \n",
       "\n",
       "              stays_nights    adults  children    babies  meal_BB  meal_FB  \\\n",
       "arrival_date                                                                 \n",
       "2015/7/1          3.048544  1.805825  0.019417  0.000000       35        1   \n",
       "2015/7/2          5.694444  1.972222  0.055556  0.000000       27        1   \n",
       "2015/7/3          4.324324  2.000000  0.081081  0.000000       22        0   \n",
       "2015/7/4          5.311111  1.977778  0.111111  0.044444       37        1   \n",
       "2015/7/5          6.108108  1.945946  0.216216  0.000000       26        0   \n",
       "...                    ...       ...       ...       ...      ...      ...   \n",
       "2017/3/27         2.982456  1.842105  0.000000  0.000000       99        0   \n",
       "2017/3/28         3.820896  1.791045  0.044776  0.014925       54        0   \n",
       "2017/3/29         2.800000  1.653846  0.053846  0.015385      104        0   \n",
       "2017/3/30         3.596774  1.725806  0.040323  0.024194       85        0   \n",
       "2017/3/31         3.084615  1.846154  0.069231  0.000000       98        0   \n",
       "\n",
       "              ...  wait_less_than_3  wait_between_3_30  wait_greater_than_30  \\\n",
       "arrival_date  ...                                                              \n",
       "2015/7/1      ...               103                  0                     0   \n",
       "2015/7/2      ...                36                  0                     0   \n",
       "2015/7/3      ...                37                  0                     0   \n",
       "2015/7/4      ...                45                  0                     0   \n",
       "2015/7/5      ...                37                  0                     0   \n",
       "...           ...               ...                ...                   ...   \n",
       "2017/3/27     ...               114                  0                     0   \n",
       "2017/3/28     ...                67                  0                     0   \n",
       "2017/3/29     ...               130                  0                     0   \n",
       "2017/3/30     ...               124                  0                     0   \n",
       "2017/3/31     ...               130                  0                     0   \n",
       "\n",
       "              contract  group  transient  transient_party  \\\n",
       "arrival_date                                                \n",
       "2015/7/1             6      0         97                0   \n",
       "2015/7/2            13      0         20                3   \n",
       "2015/7/3             6      0         22                9   \n",
       "2015/7/4             7      0         26               12   \n",
       "2015/7/5             9      1         27                0   \n",
       "...                ...    ...        ...              ...   \n",
       "2017/3/27            0      2         67               45   \n",
       "2017/3/28            0      1         64                2   \n",
       "2017/3/29            0      3        125                2   \n",
       "2017/3/30            3      0        102               19   \n",
       "2017/3/31            4      1        123                2   \n",
       "\n",
       "              mean_required_car_parking_space  special_requests_ratio  quatity  \n",
       "arrival_date                                                                    \n",
       "2015/7/1                             0.038835                0.184466      103  \n",
       "2015/7/2                             0.138889                0.500000       36  \n",
       "2015/7/3                             0.189189                0.243243       37  \n",
       "2015/7/4                             0.155556                0.488889       45  \n",
       "2015/7/5                             0.351351                0.378378       37  \n",
       "...                                       ...                     ...      ...  \n",
       "2017/3/27                            0.070175                0.675439      114  \n",
       "2017/3/28                            0.059701                0.492537       67  \n",
       "2017/3/29                            0.100000                0.484615      130  \n",
       "2017/3/30                            0.072581                0.508065      124  \n",
       "2017/3/31                            0.061538                0.592308      130  \n",
       "\n",
       "[640 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess=pd.read_csv('preprocess.csv', engine='python',index_col=\"arrival_date\")\n",
    "train=pd.read_csv('preprocess_all/preprocess_train_num_all.csv', engine='python',index_col=\"arrival_date\")\n",
    "# train=train.drop([\"label\"],axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label=pd.read_csv('train_label.csv', engine='python',index_col=\"arrival_date\")\n",
    "# test_nolabel = pd.read_csv('test_nolabel.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3125    0.4921875 0.3515625 0.421875  0.484375 ]\n",
      "0.4125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "tree = DecisionTreeClassifier(max_depth=)\n",
    "scores = cross_val_score(tree,train,y_label,cv=5,scoring='f1_micro')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3046875 0.6328125 0.6015625 0.578125  0.546875 ]\n",
      "0.5328125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=150,max_depth=10, random_state=0)\n",
    "# scores = cross_val_score(rf,train,y_label,cv=5,scoring='neg_mean_absolute_error')\n",
    "scores = cross_val_score(rf,train,y_label,cv=5,scoring='f1_micro')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2890625 0.3515625 0.359375  0.3671875 0.359375 ]\n",
      "0.3453125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ab=AdaBoostClassifier()\n",
    "# scores = cross_val_score(ab,train,y_label,cv=5,scoring='neg_mean_absolute_error')\n",
    "scores = cross_val_score(ab,train,y_label,cv=5,scoring='f1_micro')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.328125  0.578125  0.53125   0.5546875 0.4453125]\n",
      "0.4875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(n_estimators=200)\n",
    "# scores = cross_val_score(gb,train,y_label,cv=5,scoring='neg_mean_absolute_error')\n",
    "scores = cross_val_score(gb,train,y_label,cv=5,scoring='f1_micro')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3125    0.421875  0.4140625 0.2734375 0.3828125]\n",
      "0.3609375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()\n",
    "# scores = cross_val_score(lg,train,y_label,cv=5,scoring='neg_mean_absolute_error')\n",
    "scores = cross_val_score(lg,train,y_label,cv=5,scoring='f1_micro')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2890625 0.5546875 0.5234375 0.5703125 0.5625   ]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "s = svm.SVC()\n",
    "# scores = cross_val_score(s,train,y_label,cv=5,scoring='neg_mean_absolute_error')\n",
    "scores = cross_val_score(s,train,y_label,cv=5,scoring='f1_micro')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_lstm=np.array(train)\n",
    "X_train_all = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "y_label_tr=pd.get_dummies(y_label, columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,LSTM,Embedding\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        17\n",
      "           1       0.70      0.53      0.60        30\n",
      "           2       0.55      0.54      0.55        39\n",
      "           3       0.38      0.83      0.52        24\n",
      "           4       0.00      0.00      0.00         9\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.55       128\n",
      "   macro avg       0.38      0.39      0.37       128\n",
      "weighted avg       0.53      0.55      0.53       128\n",
      "\n",
      "[[14  3  0  0  0  0  0]\n",
      " [ 0 16 13  1  0  0  0]\n",
      " [ 0  4 21 14  0  0  0]\n",
      " [ 0  0  4 20  0  0  0]\n",
      " [ 0  0  0  9  0  0  0]\n",
      " [ 0  0  0  6  0  0  0]\n",
      " [ 0  0  0  3  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.77        17\n",
      "           1       0.66      0.68      0.67        34\n",
      "           2       0.60      0.45      0.51        40\n",
      "           3       0.41      0.83      0.55        24\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57       128\n",
      "   macro avg       0.32      0.33      0.31       128\n",
      "weighted avg       0.55      0.57      0.54       128\n",
      "\n",
      "[[12  5  0  0  0  0  0  0]\n",
      " [ 2 23  7  2  0  0  0  0]\n",
      " [ 0  7 18 15  0  0  0  0]\n",
      " [ 0  0  4 20  0  0  0  0]\n",
      " [ 0  0  1  6  0  0  0  0]\n",
      " [ 0  0  0  4  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81        18\n",
      "           1       0.68      0.43      0.53        30\n",
      "           2       0.51      0.64      0.57        33\n",
      "           3       0.52      0.72      0.61        32\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.58       128\n",
      "   macro avg       0.30      0.34      0.31       128\n",
      "weighted avg       0.52      0.58      0.54       128\n",
      "\n",
      "[[17  1  0  0  0  0  0  0]\n",
      " [ 7 13  9  1  0  0  0  0]\n",
      " [ 0  5 21  7  0  0  0  0]\n",
      " [ 0  0  9 23  0  0  0  0]\n",
      " [ 0  0  2  9  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        23\n",
      "           1       0.63      0.73      0.68        26\n",
      "           2       0.64      0.47      0.55        38\n",
      "           3       0.38      0.86      0.52        21\n",
      "           4       0.00      0.00      0.00         9\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.58       128\n",
      "   macro avg       0.31      0.36      0.32       128\n",
      "weighted avg       0.54      0.58      0.54       128\n",
      "\n",
      "[[19  3  1  0  0  0  0  0]\n",
      " [ 3 19  4  0  0  0  0  0]\n",
      " [ 0  7 18 13  0  0  0  0]\n",
      " [ 0  1  2 18  0  0  0  0]\n",
      " [ 0  0  1  8  0  0  0  0]\n",
      " [ 0  0  1  6  0  0  0  0]\n",
      " [ 0  0  1  2  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        19\n",
      "           1       0.65      0.53      0.59        32\n",
      "           2       0.46      0.44      0.45        36\n",
      "           3       0.34      0.70      0.46        23\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.52       128\n",
      "   macro avg       0.29      0.32      0.30       128\n",
      "weighted avg       0.48      0.52      0.48       128\n",
      "\n",
      "[[17  2  0  0  0  0  0  0]\n",
      " [ 2 17 10  3  0  0  0  0]\n",
      " [ 0  7 16 13  0  0  0  0]\n",
      " [ 1  0  6 16  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0]\n",
      " [ 0  0  1  2  0  0  0  0]\n",
      " [ 0  0  1  3  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "kfold=KFold(5,True,0)\n",
    "cvscores = []\n",
    "cvscores_f1 = []\n",
    "for train1, test1 in kfold.split(train,y_label):\n",
    "#     print(train1)\n",
    "    X_train=np.array(train.iloc[train1])\n",
    "    X_test=np.array(train.iloc[test1])\n",
    "    y_train=y_label_tr.iloc[train1]\n",
    "    y_test=y_label_tr.iloc[test1]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(train_lstm, y_label_tr, test_size = 0.2, random_state = 0)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test,(X_test.shape[0], 1, X_test.shape[1]))\n",
    "#     print(y_train)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "    model.add(LSTM(units = 256, input_dim=42,return_sequences=True))\n",
    "    model.add(LSTM(128,return_sequences=True))#new\n",
    "    model.add(LSTM(64))#new\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['mae',f1_m,'accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=20, epochs=40, verbose=0)\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "    \n",
    "\n",
    "    y_pred = model.predict(X_test, batch_size=64, verbose=0)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "    y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "    print(classification_report(y_test_bool, y_pred_bool))\n",
    "    print(confusion_matrix(y_test_bool, y_pred_bool))\n",
    "# print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.045516073703766,\n",
       " 12.159467488527298,\n",
       " 12.27007657289505,\n",
       " 12.669649720191956,\n",
       " 11.850880086421967]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.316171050071716,\n",
       " 21.471290290355682,\n",
       " 30.50958812236786,\n",
       " 31.440362334251404,\n",
       " 35.180214047431946]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89        94\n",
      "           1       0.79      0.68      0.73       152\n",
      "           2       0.72      0.68      0.70       186\n",
      "           3       0.47      0.85      0.61       124\n",
      "           4       0.00      0.00      0.00        46\n",
      "           5       0.00      0.00      0.00        21\n",
      "           6       0.00      0.00      0.00        13\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67       640\n",
      "   macro avg       0.28      0.32      0.29       640\n",
      "weighted avg       0.61      0.67      0.63       640\n",
      "\n",
      "[[ 90   4   0   0   0   0   0   0   0   0]\n",
      " [ 17 104  29   2   0   0   0   0   0   0]\n",
      " [  0  23 126  37   0   0   0   0   0   0]\n",
      " [  1   0  17 106   0   0   0   0   0   0]\n",
      " [  0   0   2  44   0   0   0   0   0   0]\n",
      " [  0   0   0  21   0   0   0   0   0   0]\n",
      " [  0   0   1  12   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "train_lstm=np.array(train)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 256, input_dim=42,return_sequences=True))\n",
    "model.add(LSTM(128,return_sequences=True))#new\n",
    "model.add(LSTM(64))#new\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['mae',f1_m,'accuracy'])\n",
    "model.fit(X_train, y_label_tr, batch_size=20, epochs=40, verbose=0)\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "    \n",
    "\n",
    "y_pred_train = model.predict(X_train, batch_size=64, verbose=0)\n",
    "y_pred_bool_train = np.argmax(y_pred_train, axis=1)\n",
    "y_train_bool = np.argmax(np.array(y_label_tr), axis=1)\n",
    "print(classification_report(y_train_bool, y_pred_bool_train))\n",
    "print(confusion_matrix(y_train_bool, y_pred_bool_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-eab11f957f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_lstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_label_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_lstm=np.array(train)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "test_lstm=np.array(test)\n",
    "X_test = np.reshape(test_lstm, (test_lstm.shape[0], 1, test_lstm.shape[1]))\n",
    "y_label_tr=pd.get_dummies(y_label, columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-5943d1bfe3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-68a3f8168a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eta'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'objective'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'binary:logistic'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nthread'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;34m'`brew install libomp` to install OpenMP runtime.\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(train, label=y_label)\n",
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "ypred = bst.predict(test, ntree_limit=bst.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
