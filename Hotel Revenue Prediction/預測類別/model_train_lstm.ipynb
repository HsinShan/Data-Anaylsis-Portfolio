{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>hotel_Resort</th>\n",
       "      <th>hotel_City</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>stays_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>meal_BB</th>\n",
       "      <th>...</th>\n",
       "      <th>wait_less_than_3</th>\n",
       "      <th>wait_between_3_30</th>\n",
       "      <th>wait_greater_than_30</th>\n",
       "      <th>contract</th>\n",
       "      <th>group</th>\n",
       "      <th>transient</th>\n",
       "      <th>transient_party</th>\n",
       "      <th>mean_required_car_parking_space</th>\n",
       "      <th>special_requests_ratio</th>\n",
       "      <th>quatity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/7/1</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>190.291262</td>\n",
       "      <td>27</td>\n",
       "      <td>3.048544</td>\n",
       "      <td>1.805825</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.184466</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/7/2</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>69.944444</td>\n",
       "      <td>27</td>\n",
       "      <td>5.694444</td>\n",
       "      <td>1.972222</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/7/3</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>65.378378</td>\n",
       "      <td>27</td>\n",
       "      <td>4.324324</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/7/4</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>120.777778</td>\n",
       "      <td>27</td>\n",
       "      <td>5.311111</td>\n",
       "      <td>1.977778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/7/5</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>75.378378</td>\n",
       "      <td>28</td>\n",
       "      <td>6.108108</td>\n",
       "      <td>1.945946</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2017/3/27</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>96.368421</td>\n",
       "      <td>13</td>\n",
       "      <td>2.982456</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.675439</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2017/3/28</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>52.537313</td>\n",
       "      <td>13</td>\n",
       "      <td>3.820896</td>\n",
       "      <td>1.791045</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2017/3/29</td>\n",
       "      <td>51</td>\n",
       "      <td>79</td>\n",
       "      <td>41.130769</td>\n",
       "      <td>13</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.653846</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.484615</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2017/3/30</td>\n",
       "      <td>51</td>\n",
       "      <td>73</td>\n",
       "      <td>59.137097</td>\n",
       "      <td>13</td>\n",
       "      <td>3.596774</td>\n",
       "      <td>1.725806</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>19</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2017/3/31</td>\n",
       "      <td>64</td>\n",
       "      <td>76</td>\n",
       "      <td>58.053846</td>\n",
       "      <td>13</td>\n",
       "      <td>3.084615</td>\n",
       "      <td>1.846154</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date  hotel_Resort  hotel_City   lead_time  \\\n",
       "0       2015/7/1            38          65  190.291262   \n",
       "1       2015/7/2            35           1   69.944444   \n",
       "2       2015/7/3            27          10   65.378378   \n",
       "3       2015/7/4            36           9  120.777778   \n",
       "4       2015/7/5            37           0   75.378378   \n",
       "..           ...           ...         ...         ...   \n",
       "635    2017/3/27            25          89   96.368421   \n",
       "636    2017/3/28            33          34   52.537313   \n",
       "637    2017/3/29            51          79   41.130769   \n",
       "638    2017/3/30            51          73   59.137097   \n",
       "639    2017/3/31            64          76   58.053846   \n",
       "\n",
       "     arrival_date_week_number  stays_nights    adults  children    babies  \\\n",
       "0                          27      3.048544  1.805825  0.019417  0.000000   \n",
       "1                          27      5.694444  1.972222  0.055556  0.000000   \n",
       "2                          27      4.324324  2.000000  0.081081  0.000000   \n",
       "3                          27      5.311111  1.977778  0.111111  0.044444   \n",
       "4                          28      6.108108  1.945946  0.216216  0.000000   \n",
       "..                        ...           ...       ...       ...       ...   \n",
       "635                        13      2.982456  1.842105  0.000000  0.000000   \n",
       "636                        13      3.820896  1.791045  0.044776  0.014925   \n",
       "637                        13      2.800000  1.653846  0.053846  0.015385   \n",
       "638                        13      3.596774  1.725806  0.040323  0.024194   \n",
       "639                        13      3.084615  1.846154  0.069231  0.000000   \n",
       "\n",
       "     meal_BB  ...  wait_less_than_3  wait_between_3_30  wait_greater_than_30  \\\n",
       "0         35  ...               103                  0                     0   \n",
       "1         27  ...                36                  0                     0   \n",
       "2         22  ...                37                  0                     0   \n",
       "3         37  ...                45                  0                     0   \n",
       "4         26  ...                37                  0                     0   \n",
       "..       ...  ...               ...                ...                   ...   \n",
       "635       99  ...               114                  0                     0   \n",
       "636       54  ...                67                  0                     0   \n",
       "637      104  ...               130                  0                     0   \n",
       "638       85  ...               124                  0                     0   \n",
       "639       98  ...               130                  0                     0   \n",
       "\n",
       "     contract  group  transient  transient_party  \\\n",
       "0           6      0         97                0   \n",
       "1          13      0         20                3   \n",
       "2           6      0         22                9   \n",
       "3           7      0         26               12   \n",
       "4           9      1         27                0   \n",
       "..        ...    ...        ...              ...   \n",
       "635         0      2         67               45   \n",
       "636         0      1         64                2   \n",
       "637         0      3        125                2   \n",
       "638         3      0        102               19   \n",
       "639         4      1        123                2   \n",
       "\n",
       "     mean_required_car_parking_space  special_requests_ratio  quatity  \n",
       "0                           0.038835                0.184466      103  \n",
       "1                           0.138889                0.500000       36  \n",
       "2                           0.189189                0.243243       37  \n",
       "3                           0.155556                0.488889       45  \n",
       "4                           0.351351                0.378378       37  \n",
       "..                               ...                     ...      ...  \n",
       "635                         0.070175                0.675439      114  \n",
       "636                         0.059701                0.492537       67  \n",
       "637                         0.100000                0.484615      130  \n",
       "638                         0.072581                0.508065      124  \n",
       "639                         0.061538                0.592308      130  \n",
       "\n",
       "[640 rows x 43 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess=pd.read_csv('preprocess.csv', engine='python',index_col=\"arrival_date\")\n",
    "train=pd.read_csv('preprocess_all/preprocess_train_num_all.csv', engine='python')\n",
    "# train=train.drop([\"label\"],axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_0.0</th>\n",
       "      <th>label_1.0</th>\n",
       "      <th>label_2.0</th>\n",
       "      <th>label_3.0</th>\n",
       "      <th>label_4.0</th>\n",
       "      <th>label_5.0</th>\n",
       "      <th>label_6.0</th>\n",
       "      <th>label_7.0</th>\n",
       "      <th>label_8.0</th>\n",
       "      <th>label_9.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-03</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-04</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-05</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label_0.0  label_1.0  label_2.0  label_3.0  label_4.0  \\\n",
       "arrival_date                                                          \n",
       "2015-07-01            0          0          1          0          0   \n",
       "2015-07-02            0          1          0          0          0   \n",
       "2015-07-03            0          1          0          0          0   \n",
       "2015-07-04            0          1          0          0          0   \n",
       "2015-07-05            0          1          0          0          0   \n",
       "...                 ...        ...        ...        ...        ...   \n",
       "2017-03-27            0          0          1          0          0   \n",
       "2017-03-28            0          1          0          0          0   \n",
       "2017-03-29            0          0          1          0          0   \n",
       "2017-03-30            0          0          0          1          0   \n",
       "2017-03-31            0          0          0          1          0   \n",
       "\n",
       "              label_5.0  label_6.0  label_7.0  label_8.0  label_9.0  \n",
       "arrival_date                                                         \n",
       "2015-07-01            0          0          0          0          0  \n",
       "2015-07-02            0          0          0          0          0  \n",
       "2015-07-03            0          0          0          0          0  \n",
       "2015-07-04            0          0          0          0          0  \n",
       "2015-07-05            0          0          0          0          0  \n",
       "...                 ...        ...        ...        ...        ...  \n",
       "2017-03-27            0          0          0          0          0  \n",
       "2017-03-28            0          0          0          0          0  \n",
       "2017-03-29            0          0          0          0          0  \n",
       "2017-03-30            0          0          0          0          0  \n",
       "2017-03-31            0          0          0          0          0  \n",
       "\n",
       "[640 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label=pd.read_csv('train_label.csv', engine='python',index_col=\"arrival_date\")\n",
    "# test_nolabel = pd.read_csv('test_nolabel.csv', engine='python')\n",
    "y_label_tr=pd.get_dummies(y_label, columns=[\"label\"])\n",
    "y_label_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augFeatures(train):\n",
    "    train[\"arrival_date\"] = pd.to_datetime(train[\"arrival_date\"])\n",
    "    train[\"year\"] = train[\"arrival_date\"].dt.year\n",
    "    train[\"month\"] = train[\"arrival_date\"].dt.month\n",
    "    train[\"date\"] = train[\"arrival_date\"].dt.day\n",
    "    train[\"day\"] = train[\"arrival_date\"].dt.dayofweek\n",
    "    train=train.drop([\"arrival_date\"],axis=1)\n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train):\n",
    "    train = train.drop([\"Date\"], axis=1)\n",
    "    train_norm = train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "    return train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train,y_label, pastDay, futureDay):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureDay-pastDay):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "#         Y_train.append(np.array(y_label.iloc[i+pastDay:i+pastDay+futureDay]))\n",
    "        yy=np.array(y_label.iloc[i+pastDay:i+pastDay+futureDay])\n",
    "        Y_train.append(np.reshape(yy, (yy.shape[1])))\n",
    "#     a=np.array(y_label.iloc[i+pastDay:i+pastDay+futureDay])\n",
    "#     print(np.reshape(a, (a.shape[1])).shape)\n",
    "#     print(np.array(Y_train).shape)\n",
    "    return np.array(X_train), np.array(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "    np.random.seed(10)\n",
    "    randomList = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return X[randomList], Y[randomList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X,Y,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildManyToOneModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n",
    "#     model.add(LSTM(units = 256, input_dim=42,return_sequences=True))\n",
    "    model.add(LSTM(64))#new\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # output shape: (1, 1)\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "#     model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,LSTM,Embedding\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# train = readTrain()\n",
    "# train_Aug = augFeatures(train)\n",
    "train_Aug=train\n",
    "train_Aug=train_Aug.drop([\"arrival_date\"],axis=1)\n",
    "print(train_Aug.shape)\n",
    "# train_norm = normalize(train_Aug)\n",
    "train_norm = train_Aug\n",
    "print(train_norm.shape)\n",
    "# change the last day and next day \n",
    "X_train, Y_train = buildTrain(train_norm,y_label_tr, 2, 1)\n",
    "print(Y_train.shape)\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "print(Y_train.shape)\n",
    "# because no return sequence, Y_train and Y_val shape must be 2 dimension\n",
    "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.2)\n",
    "\n",
    "model = buildManyToOneModel(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=200, validation_data=(X_val, Y_val), callbacks=[callback])\n",
    "y_pred = model.predict(X_val, batch_size=200, verbose=0)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "y_test_bool = np.argmax(np.array(Y_val), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 1, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_lstm=np.array(train)\n",
    "X_train_all = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "y_label_tr=pd.get_dummies(y_label, columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,LSTM,Embedding\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-0c095d301a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#     model.add(Dense(16))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#     scores = model.evaluate(X_test, y_test, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_m' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "kfold=KFold(5,True,0)\n",
    "cvscores = []\n",
    "cvscores_f1 = []\n",
    "for train1, test1 in kfold.split(train,y_label):\n",
    "#     print(train1)\n",
    "    X_train=np.array(train.iloc[train1])\n",
    "    X_test=np.array(train.iloc[test1])\n",
    "    y_train=y_label_tr.iloc[train1]\n",
    "    y_test=y_label_tr.iloc[test1]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(train_lstm, y_label_tr, test_size = 0.2, random_state = 0)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test,(X_test.shape[0], 1, X_test.shape[1]))\n",
    "#     print(y_train)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "    model.add(LSTM(units = 256, input_dim=42,return_sequences=True))\n",
    "    model.add(LSTM(128,return_sequences=True))#new\n",
    "    model.add(LSTM(64))#new\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['mae',f1_m,'accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=20, epochs=40, verbose=0)\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "    \n",
    "\n",
    "    y_pred = model.predict(X_test, batch_size=64, verbose=0)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "    y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "    print(classification_report(y_test_bool, y_pred_bool))\n",
    "    print(confusion_matrix(y_test_bool, y_pred_bool))\n",
    "# print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/1000\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.6892 - val_loss: 0.6787\n",
      "Epoch 2/1000\n",
      "512/512 [==============================] - 0s 96us/step - loss: 0.6733 - val_loss: 0.6573\n",
      "Epoch 3/1000\n",
      "512/512 [==============================] - 0s 94us/step - loss: 0.6495 - val_loss: 0.6273\n",
      "Epoch 4/1000\n",
      "512/512 [==============================] - 0s 91us/step - loss: 0.6168 - val_loss: 0.5878\n",
      "Epoch 5/1000\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.5746 - val_loss: 0.5385\n",
      "Epoch 6/1000\n",
      "512/512 [==============================] - 0s 98us/step - loss: 0.5228 - val_loss: 0.4831\n",
      "Epoch 7/1000\n",
      "512/512 [==============================] - 0s 101us/step - loss: 0.4672 - val_loss: 0.4295\n",
      "Epoch 8/1000\n",
      "512/512 [==============================] - 0s 101us/step - loss: 0.4155 - val_loss: 0.3847\n",
      "Epoch 9/1000\n",
      "512/512 [==============================] - 0s 100us/step - loss: 0.3738 - val_loss: 0.3511\n",
      "Epoch 10/1000\n",
      "512/512 [==============================] - 0s 99us/step - loss: 0.3427 - val_loss: 0.3271\n",
      "Epoch 11/1000\n",
      "512/512 [==============================] - 0s 103us/step - loss: 0.3209 - val_loss: 0.3095\n",
      "Epoch 12/1000\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.3047 - val_loss: 0.2963\n",
      "Epoch 13/1000\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.2926 - val_loss: 0.2866\n",
      "Epoch 14/1000\n",
      "512/512 [==============================] - 0s 105us/step - loss: 0.2836 - val_loss: 0.2798\n",
      "Epoch 15/1000\n",
      "512/512 [==============================] - 0s 102us/step - loss: 0.2782 - val_loss: 0.2754\n",
      "Epoch 16/1000\n",
      "512/512 [==============================] - 0s 104us/step - loss: 0.2744 - val_loss: 0.2722\n",
      "Epoch 17/1000\n",
      "512/512 [==============================] - 0s 103us/step - loss: 0.2718 - val_loss: 0.2696\n",
      "Epoch 18/1000\n",
      "512/512 [==============================] - 0s 107us/step - loss: 0.2701 - val_loss: 0.2677\n",
      "Epoch 19/1000\n",
      "512/512 [==============================] - 0s 108us/step - loss: 0.2689 - val_loss: 0.2666\n",
      "Epoch 20/1000\n",
      "512/512 [==============================] - 0s 102us/step - loss: 0.2682 - val_loss: 0.2660\n",
      "Epoch 21/1000\n",
      "512/512 [==============================] - 0s 107us/step - loss: 0.2678 - val_loss: 0.2656\n",
      "Epoch 22/1000\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.2673 - val_loss: 0.2652\n",
      "Epoch 23/1000\n",
      "512/512 [==============================] - 0s 109us/step - loss: 0.2668 - val_loss: 0.2648\n",
      "Epoch 24/1000\n",
      "512/512 [==============================] - 0s 107us/step - loss: 0.2664 - val_loss: 0.2645\n",
      "Epoch 25/1000\n",
      "512/512 [==============================] - 0s 108us/step - loss: 0.2659 - val_loss: 0.2642\n",
      "Epoch 26/1000\n",
      "512/512 [==============================] - 0s 108us/step - loss: 0.2655 - val_loss: 0.2637\n",
      "Epoch 27/1000\n",
      "512/512 [==============================] - 0s 107us/step - loss: 0.2652 - val_loss: 0.2633\n",
      "Epoch 28/1000\n",
      "512/512 [==============================] - 0s 104us/step - loss: 0.2649 - val_loss: 0.2631\n",
      "Epoch 29/1000\n",
      "512/512 [==============================] - 0s 100us/step - loss: 0.2647 - val_loss: 0.2629\n",
      "Epoch 30/1000\n",
      "512/512 [==============================] - 0s 102us/step - loss: 0.2643 - val_loss: 0.2626\n",
      "Epoch 31/1000\n",
      "512/512 [==============================] - 0s 95us/step - loss: 0.2641 - val_loss: 0.2623\n",
      "Epoch 32/1000\n",
      "512/512 [==============================] - 0s 95us/step - loss: 0.2639 - val_loss: 0.2622\n",
      "Epoch 33/1000\n",
      "512/512 [==============================] - 0s 98us/step - loss: 0.2638 - val_loss: 0.2620\n",
      "Epoch 34/1000\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.2636 - val_loss: 0.2619\n",
      "Epoch 35/1000\n",
      "512/512 [==============================] - 0s 105us/step - loss: 0.2634 - val_loss: 0.2619\n",
      "Epoch 36/1000\n",
      "512/512 [==============================] - 0s 109us/step - loss: 0.2632 - val_loss: 0.2617\n",
      "Epoch 37/1000\n",
      "512/512 [==============================] - 0s 119us/step - loss: 0.2631 - val_loss: 0.2615\n",
      "Epoch 38/1000\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.2630 - val_loss: 0.2614\n",
      "Epoch 39/1000\n",
      "512/512 [==============================] - 0s 103us/step - loss: 0.2629 - val_loss: 0.2615\n",
      "Epoch 40/1000\n",
      "512/512 [==============================] - 0s 97us/step - loss: 0.2628 - val_loss: 0.2616\n",
      "Epoch 41/1000\n",
      "512/512 [==============================] - 0s 93us/step - loss: 0.2627 - val_loss: 0.2615\n",
      "Epoch 42/1000\n",
      "512/512 [==============================] - 0s 93us/step - loss: 0.2626 - val_loss: 0.2614\n",
      "Epoch 43/1000\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.2625 - val_loss: 0.2615\n",
      "Epoch 44/1000\n",
      "512/512 [==============================] - 0s 110us/step - loss: 0.2624 - val_loss: 0.2613\n",
      "Epoch 45/1000\n",
      "512/512 [==============================] - 0s 104us/step - loss: 0.2622 - val_loss: 0.2612\n",
      "Epoch 46/1000\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.2622 - val_loss: 0.2610\n",
      "Epoch 47/1000\n",
      "512/512 [==============================] - 0s 110us/step - loss: 0.2621 - val_loss: 0.2609\n",
      "Epoch 48/1000\n",
      "512/512 [==============================] - 0s 100us/step - loss: 0.2621 - val_loss: 0.2608\n",
      "Epoch 49/1000\n",
      "512/512 [==============================] - 0s 99us/step - loss: 0.2620 - val_loss: 0.2608\n",
      "Epoch 50/1000\n",
      "512/512 [==============================] - 0s 94us/step - loss: 0.2619 - val_loss: 0.2609\n",
      "Epoch 51/1000\n",
      "512/512 [==============================] - 0s 95us/step - loss: 0.2619 - val_loss: 0.2610\n",
      "Epoch 52/1000\n",
      "512/512 [==============================] - 0s 96us/step - loss: 0.2619 - val_loss: 0.2612\n",
      "Epoch 53/1000\n",
      "512/512 [==============================] - 0s 96us/step - loss: 0.2618 - val_loss: 0.2610\n",
      "Epoch 54/1000\n",
      "512/512 [==============================] - 0s 95us/step - loss: 0.2617 - val_loss: 0.2610\n",
      "Epoch 55/1000\n",
      "512/512 [==============================] - 0s 117us/step - loss: 0.2617 - val_loss: 0.2610\n",
      "Epoch 56/1000\n",
      "512/512 [==============================] - 0s 111us/step - loss: 0.2616 - val_loss: 0.2609\n",
      "Epoch 57/1000\n",
      "512/512 [==============================] - 0s 107us/step - loss: 0.2616 - val_loss: 0.2608\n",
      "Epoch 58/1000\n",
      "512/512 [==============================] - 0s 104us/step - loss: 0.2616 - val_loss: 0.2608\n",
      "Epoch 59/1000\n",
      "512/512 [==============================] - 0s 109us/step - loss: 0.2615 - val_loss: 0.2609\n",
      "Epoch 60/1000\n",
      "512/512 [==============================] - 0s 114us/step - loss: 0.2615 - val_loss: 0.2608\n",
      "Epoch 61/1000\n",
      "512/512 [==============================] - 0s 104us/step - loss: 0.2615 - val_loss: 0.2608\n",
      "Epoch 62/1000\n",
      "512/512 [==============================] - 0s 107us/step - loss: 0.2614 - val_loss: 0.2607\n",
      "Epoch 63/1000\n",
      "512/512 [==============================] - 0s 108us/step - loss: 0.2615 - val_loss: 0.2607\n",
      "Epoch 64/1000\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.2613 - val_loss: 0.2608\n",
      "Epoch 65/1000\n",
      "512/512 [==============================] - 0s 114us/step - loss: 0.2613 - val_loss: 0.2609\n",
      "Epoch 66/1000\n",
      "512/512 [==============================] - 0s 115us/step - loss: 0.2613 - val_loss: 0.2610\n",
      "Epoch 67/1000\n",
      "512/512 [==============================] - 0s 112us/step - loss: 0.2613 - val_loss: 0.2608\n",
      "Epoch 68/1000\n",
      "512/512 [==============================] - 0s 114us/step - loss: 0.2613 - val_loss: 0.2605\n",
      "Epoch 69/1000\n",
      "512/512 [==============================] - 0s 107us/step - loss: 0.2612 - val_loss: 0.2606\n",
      "Epoch 70/1000\n",
      "512/512 [==============================] - 0s 108us/step - loss: 0.2612 - val_loss: 0.2607\n",
      "Epoch 71/1000\n",
      "512/512 [==============================] - 0s 110us/step - loss: 0.2611 - val_loss: 0.2609\n",
      "Epoch 72/1000\n",
      "512/512 [==============================] - 0s 106us/step - loss: 0.2612 - val_loss: 0.2611\n",
      "Epoch 73/1000\n",
      "512/512 [==============================] - 0s 112us/step - loss: 0.2611 - val_loss: 0.2609\n",
      "Epoch 74/1000\n",
      "512/512 [==============================] - 0s 110us/step - loss: 0.2611 - val_loss: 0.2608\n",
      "Epoch 75/1000\n",
      "512/512 [==============================] - 0s 102us/step - loss: 0.2611 - val_loss: 0.2606\n",
      "Epoch 76/1000\n",
      "512/512 [==============================] - 0s 100us/step - loss: 0.2611 - val_loss: 0.2606\n",
      "Epoch 77/1000\n",
      "512/512 [==============================] - 0s 92us/step - loss: 0.2611 - val_loss: 0.2606\n",
      "Epoch 78/1000\n",
      "512/512 [==============================] - 0s 95us/step - loss: 0.2610 - val_loss: 0.2608\n",
      "Epoch 79/1000\n",
      "512/512 [==============================] - 0s 95us/step - loss: 0.2610 - val_loss: 0.2610\n",
      "Epoch 80/1000\n",
      "512/512 [==============================] - 0s 97us/step - loss: 0.2610 - val_loss: 0.2610\n",
      "Epoch 81/1000\n",
      "512/512 [==============================] - 0s 93us/step - loss: 0.2610 - val_loss: 0.2609\n",
      "Epoch 82/1000\n",
      "512/512 [==============================] - 0s 111us/step - loss: 0.2609 - val_loss: 0.2608\n",
      "Epoch 83/1000\n",
      "512/512 [==============================] - 0s 111us/step - loss: 0.2609 - val_loss: 0.2607\n",
      "Epoch 84/1000\n",
      "512/512 [==============================] - 0s 108us/step - loss: 0.2609 - val_loss: 0.2608\n",
      "Epoch 85/1000\n",
      "512/512 [==============================] - 0s 109us/step - loss: 0.2609 - val_loss: 0.2608\n",
      "Epoch 86/1000\n",
      "512/512 [==============================] - 0s 101us/step - loss: 0.2608 - val_loss: 0.2609\n",
      "Epoch 87/1000\n",
      "512/512 [==============================] - 0s 98us/step - loss: 0.2609 - val_loss: 0.2610\n",
      "Epoch 88/1000\n",
      "512/512 [==============================] - 0s 96us/step - loss: 0.2609 - val_loss: 0.2611\n",
      "Epoch 00088: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.00      0.00      0.00        31\n",
      "           2       0.27      1.00      0.42        34\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27       128\n",
      "   macro avg       0.03      0.12      0.05       128\n",
      "weighted avg       0.07      0.27      0.11       128\n",
      "\n",
      "[[ 0  0 20  0  0  0  0  0]\n",
      " [ 0  0 31  0  0  0  0  0]\n",
      " [ 0  0 34  0  0  0  0  0]\n",
      " [ 0  0 27  0  0  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train2=train.drop([\"arrival_date\"],axis=1)\n",
    "train2 = augFeatures(train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train2, y_label_tr, test_size=0.2, random_state=42)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "# y_train=y_label_tr.iloc[train1]\n",
    "# y_test=y_label_tr.iloc[test1]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(train_lstm, y_label_tr, test_size = 0.2, random_state = 0)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test,(X_test.shape[0], 1, X_test.shape[1]))\n",
    "#     print(y_train)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "# model.add(LSTM(units = 128, input_dim=42,return_sequences=True))\n",
    "model.add(LSTM(units = 256, input_dim=46,return_sequences=True))\n",
    "model.add(LSTM(128,return_sequences=True))#new\n",
    "model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['mae',f1_m,'accuracy'])\n",
    "# model.fit(X_train, y_train, batch_size=20, epochs=40, verbose=0)\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=200, validation_data=(X_test, y_test), callbacks=[callback])\n",
    "y_pred = model.predict(X_test, batch_size=200, verbose=0)  \n",
    "\n",
    "# y_pred = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2015/7/1', 38, 65, ..., 0.038834951, 0.18446601899999998, 103],\n",
       "       ['2015/7/2', 35, 1, ..., 0.13888888900000002, 0.5, 36],\n",
       "       ['2015/7/3', 27, 10, ..., 0.18918918899999998, 0.243243243, 37],\n",
       "       ...,\n",
       "       ['2017/3/29', 51, 79, ..., 0.1, 0.484615385, 130],\n",
       "       ['2017/3/30', 51, 73, ..., 0.072580645, 0.508064516, 124],\n",
       "       ['2017/3/31', 64, 76, ..., 0.061538462, 0.592307692, 130]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        94\n",
      "           1       1.00      1.00      1.00       152\n",
      "           2       0.99      0.99      0.99       186\n",
      "           3       1.00      0.99      1.00       124\n",
      "           4       0.96      0.98      0.97        46\n",
      "           5       0.95      1.00      0.98        21\n",
      "           6       0.87      1.00      0.93        13\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.99       640\n",
      "   macro avg       0.78      0.80      0.79       640\n",
      "weighted avg       0.99      0.99      0.99       640\n",
      "\n",
      "[[ 94   0   0   0   0   0   0   0   0   0]\n",
      " [  0 152   0   0   0   0   0   0   0   0]\n",
      " [  0   0 185   0   1   0   0   0   0   0]\n",
      " [  0   0   0 123   1   0   0   0   0   0]\n",
      " [  0   0   1   0  45   0   0   0   0   0]\n",
      " [  0   0   0   0   0  21   0   0   0   0]\n",
      " [  0   0   0   0   0   0  13   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "# train_lstm=np.array(train)\n",
    "train_lstm=train.drop([\"arrival_date\"],axis=1)\n",
    "train_lstm=np.array(train_lstm)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train2, y_label_tr, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 256, input_dim=42,return_sequences=True))\n",
    "model.add(LSTM(128,return_sequences=True))#new\n",
    "model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "model.fit(X_train, y_label_tr, batch_size=200, epochs=1000, verbose=0,callbacks=[callback])\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "\n",
    "y_pred_train = model.predict(X_train, batch_size=64, verbose=0)\n",
    "y_pred_bool_train = np.argmax(y_pred_train, axis=1)\n",
    "y_train_bool = np.argmax(np.array(y_label_tr), axis=1)\n",
    "print(classification_report(y_train_bool, y_pred_bool_train))\n",
    "print(confusion_matrix(y_train_bool, y_pred_bool_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.0171875\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(y_train_bool)):\n",
    "    error.append(y_train_bool[i] - y_pred_bool_train[i])\n",
    "\n",
    "# print(\"Errors: \", error)\n",
    "# print(error)\n",
    "\n",
    "absError = []\n",
    "for val in error:\n",
    "    absError.append(abs(val))#誤差絕對值\n",
    "\n",
    "# print(\"Absolute Value of Error: \", absError)\n",
    "from math import sqrt\n",
    "print(\"MAE = \", sum(absError) / len(absError))#平均絕對誤差MAE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.80      0.71        20\n",
      "           1       0.64      0.68      0.66        31\n",
      "           2       0.60      0.44      0.51        34\n",
      "           3       0.45      0.52      0.48        27\n",
      "           4       0.33      0.40      0.36        10\n",
      "           5       0.50      0.33      0.40         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.55       128\n",
      "   macro avg       0.40      0.40      0.39       128\n",
      "weighted avg       0.55      0.55      0.54       128\n",
      "\n",
      "[[16  3  1  0  0  0  0  0]\n",
      " [ 7 21  3  0  0  0  0  0]\n",
      " [ 0  8 15  9  2  0  0  0]\n",
      " [ 2  1  5 14  5  0  0  0]\n",
      " [ 0  0  0  6  4  0  0  0]\n",
      " [ 0  0  0  1  1  1  0  0]\n",
      " [ 0  0  0  1  0  1  0  0]\n",
      " [ 0  0  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# train_lstm=np.array(train)\n",
    "train_lstm=train.drop([\"arrival_date\"],axis=1)\n",
    "train_lstm=np.array(train_lstm)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_label_tr, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 256, input_dim=42,return_sequences=True))\n",
    "model.add(LSTM(128,return_sequences=True))#new\n",
    "model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=1000, verbose=0,callbacks=[callback])\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "\n",
    "y_pred_train = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred_bool_test = np.argmax(y_pred_train, axis=1)\n",
    "y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool_test))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.578125\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(y_test_bool)):\n",
    "    error.append(y_test_bool[i] - y_pred_bool_test[i])\n",
    "\n",
    "# print(\"Errors: \", error)\n",
    "# print(error)\n",
    "\n",
    "absError = []\n",
    "for val in error:\n",
    "    absError.append(abs(val))#誤差絕對值\n",
    "\n",
    "# print(\"Absolute Value of Error: \", absError)\n",
    "from math import sqrt\n",
    "print(\"MAE = \", sum(absError) / len(absError))#平均絕對誤差MAE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79        20\n",
      "           1       0.71      0.77      0.74        31\n",
      "           2       0.58      0.53      0.55        34\n",
      "           3       0.33      0.33      0.33        27\n",
      "           4       0.38      0.30      0.33        10\n",
      "           5       0.20      0.33      0.25         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       128\n",
      "   macro avg       0.37      0.39      0.37       128\n",
      "weighted avg       0.54      0.56      0.55       128\n",
      "\n",
      "[[17  3  0  0  0  0  0  0]\n",
      " [ 4 24  3  0  0  0  0  0]\n",
      " [ 0  6 18 10  0  0  0  0]\n",
      " [ 2  1  9  9  3  3  0  0]\n",
      " [ 0  0  1  6  3  0  0  0]\n",
      " [ 0  0  0  1  1  1  0  0]\n",
      " [ 0  0  0  0  1  1  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# train_lstm=np.array(train)\n",
    "train_lstm=train.drop([\"arrival_date\"],axis=1)\n",
    "train_lstm=np.array(train_lstm)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_label_tr, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 256, input_dim=42,return_sequences=True))\n",
    "model.add(LSTM(128))#new\n",
    "# model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=1000, verbose=0,callbacks=[callback])\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "\n",
    "y_pred_train = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred_bool_test = np.argmax(y_pred_train, axis=1)\n",
    "y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool_test))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.5625\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(y_test_bool)):\n",
    "    error.append(y_test_bool[i] - y_pred_bool_test[i])\n",
    "\n",
    "# print(\"Errors: \", error)\n",
    "# print(error)\n",
    "\n",
    "absError = []\n",
    "for val in error:\n",
    "    absError.append(abs(val))#誤差絕對值\n",
    "\n",
    "# print(\"Absolute Value of Error: \", absError)\n",
    "from math import sqrt\n",
    "print(\"MAE = \", sum(absError) / len(absError))#平均絕對誤差MAE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74        20\n",
      "           1       0.68      0.68      0.68        31\n",
      "           2       0.56      0.65      0.60        34\n",
      "           3       0.52      0.48      0.50        27\n",
      "           4       0.43      0.30      0.35        10\n",
      "           5       0.33      0.33      0.33         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59       128\n",
      "   macro avg       0.40      0.40      0.40       128\n",
      "weighted avg       0.57      0.59      0.58       128\n",
      "\n",
      "[[16  3  1  0  0  0  0  0]\n",
      " [ 6 21  4  0  0  0  0  0]\n",
      " [ 0  7 22  5  0  0  0  0]\n",
      " [ 1  0 10 13  2  1  0  0]\n",
      " [ 0  0  1  6  3  0  0  0]\n",
      " [ 0  0  0  1  1  1  0  0]\n",
      " [ 0  0  0  0  1  1  0  0]\n",
      " [ 0  0  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# train_lstm=np.array(train)\n",
    "train_lstm=train.drop([\"arrival_date\"],axis=1)\n",
    "train_lstm=np.array(train_lstm)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_label_tr, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 256, input_dim=42,return_sequences=True))\n",
    "model.add(LSTM(128))#new\n",
    "# model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=1000, verbose=0,callbacks=[callback])\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "\n",
    "y_pred_train = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred_bool_test = np.argmax(y_pred_train, axis=1)\n",
    "y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool_test))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.5078125\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(y_test_bool)):\n",
    "    error.append(y_test_bool[i] - y_pred_bool_test[i])\n",
    "\n",
    "# print(\"Errors: \", error)\n",
    "# print(error)\n",
    "\n",
    "absError = []\n",
    "for val in error:\n",
    "    absError.append(abs(val))#誤差絕對值\n",
    "\n",
    "# print(\"Absolute Value of Error: \", absError)\n",
    "from math import sqrt\n",
    "print(\"MAE = \", sum(absError) / len(absError))#平均絕對誤差MAE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        20\n",
      "           1       0.67      0.65      0.66        31\n",
      "           2       0.49      0.56      0.52        34\n",
      "           3       0.48      0.48      0.48        27\n",
      "           4       0.43      0.30      0.35        10\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       128\n",
      "   macro avg       0.35      0.35      0.35       128\n",
      "weighted avg       0.54      0.56      0.55       128\n",
      "\n",
      "[[17  1  2  0  0  0  0  0]\n",
      " [ 6 20  5  0  0  0  0  0]\n",
      " [ 0  8 19  7  0  0  0  0]\n",
      " [ 1  0 10 13  3  0  0  0]\n",
      " [ 0  1  1  5  3  0  0  0]\n",
      " [ 0  0  1  1  1  0  0  0]\n",
      " [ 0  0  0  1  0  1  0  0]\n",
      " [ 0  0  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# train_lstm=np.array(train)\n",
    "train_lstm=train.drop([\"arrival_date\"],axis=1)\n",
    "train_lstm=np.array(train_lstm)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_label_tr, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 256, input_dim=42))\n",
    "# model.add(LSTM(128))#new\n",
    "# model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=1000, verbose=0,callbacks=[callback])\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "\n",
    "y_pred_train = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred_bool_test = np.argmax(y_pred_train, axis=1)\n",
    "y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool_test))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.578125\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(y_test_bool)):\n",
    "    error.append(y_test_bool[i] - y_pred_bool_test[i])\n",
    "\n",
    "# print(\"Errors: \", error)\n",
    "# print(error)\n",
    "\n",
    "absError = []\n",
    "for val in error:\n",
    "    absError.append(abs(val))#誤差絕對值\n",
    "\n",
    "# print(\"Absolute Value of Error: \", absError)\n",
    "from math import sqrt\n",
    "print(\"MAE = \", sum(absError) / len(absError))#平均絕對誤差MAE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82        20\n",
      "           1       0.69      0.87      0.77        31\n",
      "           2       0.56      0.53      0.55        34\n",
      "           3       0.54      0.56      0.55        27\n",
      "           4       0.33      0.30      0.32        10\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62       128\n",
      "   macro avg       0.37      0.38      0.37       128\n",
      "weighted avg       0.59      0.62      0.60       128\n",
      "\n",
      "[[16  2  2  0  0  0  0  0]\n",
      " [ 2 27  2  0  0  0  0  0]\n",
      " [ 0  8 18  7  1  0  0  0]\n",
      " [ 1  2  7 15  2  0  0  0]\n",
      " [ 0  0  2  5  3  0  0  0]\n",
      " [ 0  0  0  1  2  0  0  0]\n",
      " [ 0  0  0  0  1  1  0  0]\n",
      " [ 0  0  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# train_lstm=np.array(train)\n",
    "train_lstm=train.drop([\"arrival_date\"],axis=1)\n",
    "train_lstm=np.array(train_lstm)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_label_tr, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 256, input_dim=42))\n",
    "# model.add(LSTM(128))#new\n",
    "# model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=1000, verbose=0,callbacks=[callback])\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "\n",
    "y_pred_train = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred_bool_test = np.argmax(y_pred_train, axis=1)\n",
    "y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool_test))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.515625\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(y_test_bool)):\n",
    "    error.append(y_test_bool[i] - y_pred_bool_test[i])\n",
    "\n",
    "# print(\"Errors: \", error)\n",
    "# print(error)\n",
    "\n",
    "absError = []\n",
    "for val in error:\n",
    "    absError.append(abs(val))#誤差絕對值\n",
    "\n",
    "# print(\"Absolute Value of Error: \", absError)\n",
    "from math import sqrt\n",
    "print(\"MAE = \", sum(absError) / len(absError))#平均絕對誤差MAE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        20\n",
      "           1       0.65      0.71      0.68        31\n",
      "           2       0.53      0.56      0.54        34\n",
      "           3       0.46      0.41      0.43        27\n",
      "           4       0.40      0.40      0.40        10\n",
      "           5       0.33      0.33      0.33         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       128\n",
      "   macro avg       0.39      0.39      0.39       128\n",
      "weighted avg       0.54      0.56      0.55       128\n",
      "\n",
      "[[15  3  2  0  0  0  0  0]\n",
      " [ 4 22  5  0  0  0  0  0]\n",
      " [ 0  7 19  5  3  0  0  0]\n",
      " [ 2  1 10 11  2  1  0  0]\n",
      " [ 0  0  0  6  4  0  0  0]\n",
      " [ 0  0  0  2  0  1  0  0]\n",
      " [ 0  0  0  0  1  1  0  0]\n",
      " [ 0  1  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# train_lstm=np.array(train)\n",
    "train_lstm=train.drop([\"arrival_date\"],axis=1)\n",
    "train_lstm=np.array(train_lstm)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_label_tr, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 256, input_dim=42))\n",
    "# model.add(LSTM(128))#new\n",
    "# model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=1000, verbose=0,callbacks=[callback])\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "\n",
    "y_pred_train = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred_bool_test = np.argmax(y_pred_train, axis=1)\n",
    "y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool_test))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.6015625\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(y_test_bool)):\n",
    "    error.append(y_test_bool[i] - y_pred_bool_test[i])\n",
    "\n",
    "# print(\"Errors: \", error)\n",
    "# print(error)\n",
    "\n",
    "absError = []\n",
    "for val in error:\n",
    "    absError.append(abs(val))#誤差絕對值\n",
    "\n",
    "# print(\"Absolute Value of Error: \", absError)\n",
    "from math import sqrt\n",
    "print(\"MAE = \", sum(absError) / len(absError))#平均絕對誤差MAE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.75      0.70        20\n",
      "           1       0.59      0.65      0.62        31\n",
      "           2       0.54      0.41      0.47        34\n",
      "           3       0.45      0.52      0.48        27\n",
      "           4       0.30      0.30      0.30        10\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.52       128\n",
      "   macro avg       0.32      0.33      0.32       128\n",
      "weighted avg       0.51      0.52      0.51       128\n",
      "\n",
      "[[15  3  1  1  0  0  0  0]\n",
      " [ 6 20  5  0  0  0  0  0]\n",
      " [ 1  8 14  9  2  0  0  0]\n",
      " [ 1  3  3 14  4  2  0  0]\n",
      " [ 0  0  2  4  3  1  0  0]\n",
      " [ 0  0  0  2  1  0  0  0]\n",
      " [ 0  0  0  1  0  1  0  0]\n",
      " [ 0  0  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# train_lstm=np.array(train)\n",
    "train_lstm=train.drop([\"arrival_date\"],axis=1)\n",
    "train_lstm=np.array(train_lstm)\n",
    "X_train = np.reshape(train_lstm, (train_lstm.shape[0], 1, train_lstm.shape[1]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_label_tr, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "#     model.add(LSTM(units = 256, input_dim=42))\n",
    "model.add(LSTM(units = 128, input_dim=42))\n",
    "# model.add(LSTM(128))#new\n",
    "# model.add(LSTM(64))#new\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(16))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"auto\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=1000, verbose=0,callbacks=[callback])\n",
    "#     scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "\n",
    "y_pred_train = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred_bool_test = np.argmax(y_pred_train, axis=1)\n",
    "y_test_bool = np.argmax(np.array(y_test), axis=1)\n",
    "print(classification_report(y_test_bool, y_pred_bool_test))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.6796875\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(y_test_bool)):\n",
    "    error.append(y_test_bool[i] - y_pred_bool_test[i])\n",
    "\n",
    "# print(\"Errors: \", error)\n",
    "# print(error)\n",
    "\n",
    "absError = []\n",
    "for val in error:\n",
    "    absError.append(abs(val))#誤差絕對值\n",
    "\n",
    "# print(\"Absolute Value of Error: \", absError)\n",
    "from math import sqrt\n",
    "print(\"MAE = \", sum(absError) / len(absError))#平均絕對誤差MAE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
